# Layered Cache Adapter - Documenta√ß√£o Completa

> **M√≥dulo:** `shared/utils/cache/LayeredCacheAdapter`
> **Vers√£o:** 1.0.0
> **Arquivo:** `src/shared/utils/cache/LayeredCacheAdapter.ts`

---

## üìã √çndice

1. [Vis√£o Geral](#vis√£o-geral)
2. [Arquitetura L1 + L2](#arquitetura-l1--l2)
3. [Estrat√©gias de Opera√ß√£o](#estrat√©gias-de-opera√ß√£o)
4. [M√©todos da Classe](#m√©todos-da-classe)
5. [Estat√≠sticas](#estat√≠sticas)
6. [Performance](#performance)
7. [Casos de Uso](#casos-de-uso)
8. [Exemplos Pr√°ticos](#exemplos-pr√°ticos)
9. [Compara√ß√£o com Single-Layer](#compara√ß√£o-com-single-layer)
10. [Troubleshooting](#troubleshooting)

---

## üéØ Vis√£o Geral

Implementa estrat√©gia de cache em **duas camadas** para m√°xima performance e disponibilidade, combinando velocidade da mem√≥ria local com persist√™ncia do Redis distribu√≠do.

### Prop√≥sito

- ‚úÖ **Performance m√°xima:** L1 mem√≥ria ~1ms
- ‚úÖ **Compartilhamento:** L2 Redis entre inst√¢ncias
- ‚úÖ **Redund√¢ncia:** Fallback L1 ‚Üî L2
- ‚úÖ **Alta disponibilidade:** L1 funciona se Redis cair
- ‚úÖ **Promo√ß√£o inteligente:** Hot data migra para L1

### Benef√≠cios

| Benef√≠cio | Descri√ß√£o |
|-----------|-----------|
| **Ultra r√°pido** | L1 responde em < 1ms (sem lat√™ncia de rede) |
| **Distribu√≠do** | L2 compartilha dados entre inst√¢ncias |
| **Resiliente** | Continua funcionando com falha parcial |
| **Otimizado** | Hot data automaticamente promovido para L1 |
| **Escal√°vel** | Suporta m√∫ltiplas inst√¢ncias load-balanced |

---

## üèóÔ∏è Arquitetura L1 + L2

### Camadas

#### L1 (Layer 1) - Cache Local

**Implementa√ß√£o:** `MemoryCacheAdapter`

**Caracter√≠sticas:**
- ‚úÖ **Velocidade:** < 1ms (acesso direto √† mem√≥ria)
- ‚úÖ **Zero lat√™ncia:** Sem rede envolvida
- ‚úÖ **Simples:** N√£o requer servi√ßos externos
- ‚ùå **Local:** N√£o compartilhado entre inst√¢ncias
- ‚ùå **Vol√°til:** Perdido em restart
- ‚ùå **Limitado:** Restrito pela RAM dispon√≠vel

**Casos ideais:**
- Hot data (dados muito acessados)
- Dados tempor√°rios
- Sess√µes de curta dura√ß√£o

#### L2 (Layer 2) - Cache Distribu√≠do

**Implementa√ß√£o:** `RedisCacheAdapter`

**Caracter√≠sticas:**
- ‚úÖ **Compartilhado:** Entre todas inst√¢ncias
- ‚úÖ **Persistente:** Opcional (Redis AOF/RDB)
- ‚úÖ **Escal√°vel:** Horizontalmente
- ‚úÖ **Grande capacidade:** N√£o limitado por RAM local
- ‚ùå **Lat√™ncia de rede:** ~1-10ms
- ‚ùå **Depend√™ncia:** Requer Redis dispon√≠vel

**Casos ideais:**
- Cold data (dados menos acessados)
- Dados compartilhados
- Cache persistente

### Diagrama de Arquitetura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   LayeredCacheAdapter                    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   L1 (Memory)    ‚îÇ       ‚îÇ   L2 (Redis)     ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ                  ‚îÇ       ‚îÇ                  ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ < 1ms         ‚îÇ       ‚îÇ  ‚Ä¢ 1-10ms        ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Local         ‚îÇ       ‚îÇ  ‚Ä¢ Distribu√≠do   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Vol√°til       ‚îÇ       ‚îÇ  ‚Ä¢ Persistente   ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  ‚Ä¢ Hot data      ‚îÇ       ‚îÇ  ‚Ä¢ Cold data     ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ          ‚Üì                           ‚Üì                   ‚îÇ
‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                      ‚Üì                                    ‚îÇ
‚îÇ              Dados em cache                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üîÑ Estrat√©gias de Opera√ß√£o

### Estrat√©gia de Leitura (GET)

**Algoritmo em cascata:**

```
1. Buscar em L1 (mem√≥ria)
   ‚îú‚îÄ Encontrou? ‚Üí Retornar (HIT L1) ‚úÖ
   ‚îî‚îÄ N√£o encontrou? ‚Üí Continuar

2. Buscar em L2 (Redis)
   ‚îú‚îÄ Encontrou? ‚Üí Promover para L1 + Retornar (HIT L2) ‚úÖ
   ‚îî‚îÄ N√£o encontrou? ‚Üí Retornar undefined (MISS) ‚ùå
```

**Fluxo detalhado:**

```typescript
async get<T>(key: string) {
  // 1Ô∏è‚É£ Tentativa L1
  const l1Value = await this.l1.get<T>(key);
  if (l1Value !== undefined) {
    stats.l1Hits++;
    return l1Value; // ~1ms
  }
  stats.l1Misses++;

  // 2Ô∏è‚É£ Tentativa L2
  const l2Value = await this.l2.get<T>(key);
  if (l2Value !== undefined) {
    stats.l2Hits++;

    // üîº Promo√ß√£o L2 ‚Üí L1
    await this.l1.set(key, l2Value);

    return l2Value; // ~5ms primeira vez, ~1ms pr√≥xima
  }
  stats.l2Misses++;

  // ‚ùå Miss total
  return undefined;
}
```

**Exemplo de sequ√™ncia:**

```typescript
// Request 1: Primeira leitura (MISS total)
await cache.get('item:123'); // undefined
// L1: MISS, L2: MISS

await cache.set('item:123', data);

// Request 2: Segunda leitura (HIT L1)
await cache.get('item:123'); // data (~1ms)
// L1: HIT

// ... L1 expira ap√≥s TTL ...

// Request 3: Leitura ap√≥s expira√ß√£o L1 (HIT L2, promove para L1)
await cache.get('item:123'); // data (~5ms)
// L1: MISS, L2: HIT ‚Üí promove para L1

// Request 4: Leitura ap√≥s promo√ß√£o (HIT L1 novamente)
await cache.get('item:123'); // data (~1ms)
// L1: HIT
```

### Promo√ß√£o L2 ‚Üí L1

**Prop√≥sito:** Otimizar futuras leituras.

**Quando ocorre:**
- Valor encontrado em L2 mas n√£o em L1
- Indica que √© dado potencialmente "quente"

**Benef√≠cio:**
```
Primeira leitura (L2): ~5ms
Pr√≥xima leitura (L1): ~1ms
Speedup: 5x mais r√°pido
```

**Implementa√ß√£o:**
```typescript
// Hit em L2
const l2Value = await this.l2.get<T>(key);
if (l2Value !== undefined) {
  // Promove para L1 (fire-and-forget)
  this.l1.set(key, l2Value).catch(err => {
    // Falha na promo√ß√£o n√£o afeta retorno
    log.warn('Falha ao promover para L1', { key, err });
  });

  return l2Value;
}
```

---

### Estrat√©gia de Escrita (SET)

**Algoritmo simult√¢neo:**

```
1. Armazenar em L1 e L2 simultaneamente (Promise.allSettled)
   ‚îú‚îÄ Ambos OK? ‚Üí Retornar true ‚úÖ
   ‚îú‚îÄ Apenas L1 OK? ‚Üí Retornar true (L2 falhou, mas cache funciona) ‚ö†Ô∏è
   ‚îú‚îÄ Apenas L2 OK? ‚Üí Retornar true (L1 falhou, mas cache funciona) ‚ö†Ô∏è
   ‚îî‚îÄ Ambos FAIL? ‚Üí Retornar false ‚ùå
```

**Fluxo detalhado:**

```typescript
async set<T>(key: string, value: T, ttl?: number) {
  // Executa em paralelo
  const [l1Result, l2Result] = await Promise.allSettled([
    this.l1.set(key, value, ttl),
    this.l2.set(key, value, ttl)
  ]);

  const l1Ok = l1Result.status === 'fulfilled' && l1Result.value;
  const l2Ok = l2Result.status === 'fulfilled' && l2Result.value;

  // Sucesso se PELO MENOS uma camada funcionou
  return l1Ok || l2Ok;
}
```

**Cen√°rios:**

| L1 | L2 | Retorno | Situa√ß√£o |
|----|----|---------| ---------|
| ‚úÖ | ‚úÖ | `true` | Ideal: ambas armazenaram |
| ‚úÖ | ‚ùå | `true` | Redis offline, mas L1 funciona |
| ‚ùå | ‚úÖ | `true` | L1 falhou, mas L2 funciona |
| ‚ùå | ‚ùå | `false` | Problema cr√≠tico |

**Resili√™ncia:**

```typescript
// Redis cai, mas aplica√ß√£o continua
await cache.set('key', value);
// L1: OK ‚úÖ
// L2: FAIL ‚ùå (Redis offline)
// Retorna: true (cache L1 funciona)

// Pr√≥xima leitura usa L1
await cache.get('key'); // HIT L1, funciona normalmente
```

---

### Estrat√©gia de Remo√ß√£o (DELETE)

**Algoritmo simult√¢neo:**

```
1. Remover de L1 e L2 simultaneamente
2. Somar chaves removidas
3. Retornar total
```

**Fluxo:**

```typescript
async delete(key: string) {
  const [l1Result, l2Result] = await Promise.allSettled([
    this.l1.delete(key),
    this.l2.delete(key)
  ]);

  const l1Count = l1Result.status === 'fulfilled' ? l1Result.value : 0;
  const l2Count = l2Result.status === 'fulfilled' ? l2Result.value : 0;

  return l1Count + l2Count; // 0 a 2
}
```

**Poss√≠veis retornos:**

| Retorno | Significado |
|---------|-------------|
| `2` | Removido de L1 e L2 |
| `1` | Removido de apenas uma camada |
| `0` | N√£o existia em nenhuma |

---

## üìö M√©todos da Classe

### constructor(l1, l2, name?)

Cria inst√¢ncia do cache em camadas.

**Par√¢metros:**

| Par√¢metro | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-----------|------|-------------|-----------|
| **l1** | `CacheAdapter` | Sim | Adaptador L1 (mem√≥ria) |
| **l2** | `CacheAdapter` | Sim | Adaptador L2 (Redis) |
| **name** | `string` | N√£o | Nome para logging (default: 'Layered') |

**Exemplo:**

```typescript
import { MemoryCacheAdapter } from './MemoryCacheAdapter';
import { RedisCacheAdapter } from './RedisCacheAdapter';
import { LayeredCacheAdapter } from './LayeredCacheAdapter';

const l1 = new MemoryCacheAdapter(300); // TTL 5min
const l2 = new RedisCacheAdapter({
  host: 'localhost',
  port: 6379
});

const cache = new LayeredCacheAdapter(l1, l2, 'MyCache');
// Log: "MyCache cache inicializado (L1 + L2)"
```

---

### get<T>(key: string)

Busca valor com estrat√©gia em camadas.

**Retorna:**
- Valor tipado `T` se encontrado
- `undefined` se n√£o encontrado

**Exemplo:**

```typescript
interface User {
  id: string;
  name: string;
}

// Primeira tentativa (MISS)
const user1 = await cache.get<User>('user:123');
console.log(user1); // undefined

// Armazenar
await cache.set('user:123', { id: '123', name: 'John' });

// Segunda tentativa (HIT L1)
const user2 = await cache.get<User>('user:123');
console.log(user2); // { id: '123', name: 'John' } - ~1ms
```

**Estat√≠sticas atualizadas:**

```typescript
const stats = cache.getStats();

// Ap√≥s get() bem-sucedido em L1
// stats.l1.hits += 1

// Ap√≥s get() bem-sucedido em L2
// stats.l2.hits += 1

// Ap√≥s get() sem sucesso
// stats.l2.misses += 1
```

---

### set<T>(key, value, ttl?)

Armazena valor em ambas as camadas.

**Par√¢metros:**

| Par√¢metro | Tipo | Obrigat√≥rio | Descri√ß√£o |
|-----------|------|-------------|-----------|
| **key** | `string` | Sim | Chave √∫nica |
| **value** | `T` | Sim | Valor a armazenar |
| **ttl** | `number` | N√£o | Tempo de vida em segundos |

**Retorna:**
- `true` se pelo menos uma camada teve sucesso
- `false` se ambas falharam

**Exemplo:**

```typescript
// Com TTL espec√≠fico
const success = await cache.set('item:123', item, 600); // 10min
console.log(success); // true

// Com TTL padr√£o (do adapter)
await cache.set('temp:data', data);

// Verificar sucesso
if (!await cache.set('critical', value)) {
  log.error('FALHA CR√çTICA: Cache n√£o armazenou');
}
```

---

### delete(key: string)

Remove valor de ambas as camadas.

**Retorna:**
- N√∫mero de chaves removidas (0-2)

**Exemplo:**

```typescript
// Remover de ambas
const removed = await cache.delete('item:123');
console.log(removed); // 2 (L1 + L2)

// Remover quando s√≥ existe em uma
await cache.delete('item:456');
// Retorna: 1 (s√≥ estava em L1 ou L2)

// Remover inexistente
await cache.delete('nao-existe');
// Retorna: 0
```

---

### flush()

Limpa todas as chaves de ambas as camadas.

**Exemplo:**

```typescript
// Limpar tudo
await cache.flush();
// Log: "MyCache FLUSH ALL (L1 + L2)"

// ‚ö†Ô∏è Use com cuidado em produ√ß√£o
// Causa cache stampede se tr√°fego alto
```

---

### keys(pattern?)

Lista chaves de ambas as camadas (uni√£o).

**Retorna:**
- Array √∫nico de chaves (sem duplicatas)

**Exemplo:**

```typescript
// Listar todas
const allKeys = await cache.keys();
console.log(`Total: ${allKeys.length}`);

// Listar com pattern
const itemKeys = await cache.keys('item:*');
console.log(`Items: ${itemKeys.length}`);

// L1 tem: ['a', 'b', 'c']
// L2 tem: ['b', 'c', 'd']
// Retorna: ['a', 'b', 'c', 'd']
```

---

### isReady()

Verifica se pelo menos uma camada est√° dispon√≠vel.

**Retorna:**
- `true` se L1 OU L2 dispon√≠vel
- `false` se ambas indispon√≠veis

**Exemplo:**

```typescript
// Verificar sa√∫de
const ready = await cache.isReady();
if (!ready) {
  log.error('Cache completamente offline!');
}

// Cen√°rios
// L1: OK, L2: OK ‚Üí true
// L1: OK, L2: DOWN ‚Üí true (L1 funciona)
// L1: DOWN, L2: OK ‚Üí true (L2 funciona)
// L1: DOWN, L2: DOWN ‚Üí false
```

---

### close()

Fecha conex√µes de ambas as camadas.

**Exemplo:**

```typescript
// Graceful shutdown
process.on('SIGTERM', async () => {
  await cache.close();
  // Log: "MyCache fechado (L1 + L2)"
  process.exit(0);
});
```

---

### getStats()

Retorna estat√≠sticas detalhadas.

**Retorna:**

```typescript
{
  l1: {
    hits: number,
    misses: number,
    hitRate: number  // 0-100
  },
  l2: {
    hits: number,
    misses: number,
    hitRate: number
  },
  overall: {
    hits: number,
    misses: number,
    hitRate: number
  }
}
```

**Exemplo:**

```typescript
const stats = cache.getStats();

console.log(`L1 Hit Rate: ${stats.l1.hitRate}%`);
console.log(`L2 Hit Rate: ${stats.l2.hitRate}%`);
console.log(`Overall Hit Rate: ${stats.overall.hitRate}%`);

// Monitoramento
if (stats.l1.hitRate < 50) {
  log.warn('L1 pouco efetivo, considerar aumentar TTL');
}

// An√°lise
const l1Effectiveness = stats.l1.hits / stats.overall.hits * 100;
console.log(`${l1Effectiveness}% dos hits vieram do L1`);
```

---

## üìä Estat√≠sticas

### Campos Rastreados

```typescript
interface LayeredStats {
  l1Hits: number;      // Hits em L1 (mem√≥ria)
  l1Misses: number;    // Misses em L1
  l2Hits: number;      // Hits em L2 (Redis)
  l2Misses: number;    // Misses em L2
  totalHits: number;   // L1 + L2 hits
  totalMisses: number; // Misses totais
}
```

### C√°lculo de Hit Rates

```typescript
// Hit Rate L1
l1HitRate = (l1Hits / (l1Hits + l1Misses)) * 100

// Hit Rate L2
l2HitRate = (l2Hits / (l2Hits + l2Misses)) * 100

// Hit Rate Overall
overallHitRate = (totalHits / (totalHits + totalMisses)) * 100
```

### Interpreta√ß√£o

| Hit Rate | L1 | L2 | Overall | A√ß√£o |
|----------|----|----|---------|------|
| **> 80%** | üü¢ Excelente | üü¢ Excelente | üü¢ √ìtimo | Manter |
| **50-80%** | üü° Bom | üü° OK | üü° OK | Monitorar |
| **< 50%** | üî¥ Baixo | üî¥ Baixo | üî¥ Ruim | Otimizar TTL |

### Exemplo de An√°lise

```typescript
const stats = cache.getStats();

// L1 efetivo?
const l1Contribution = stats.l1.hits / stats.overall.hits;
if (l1Contribution < 0.5) {
  // Menos de 50% dos hits v√™m do L1
  log.warn('L1 subutilizado, aumentar TTL?');
}

// L2 muito usado?
const l2Contribution = stats.l2.hits / stats.overall.hits;
if (l2Contribution > 0.8) {
  // Mais de 80% dos hits v√™m do L2
  log.info('L2 muito ativo, L1 expira√ß√£o r√°pida?');
}

// Taxa de promo√ß√£o L2‚ÜíL1
const promotionRate = stats.l2.hits;
console.log(`${promotionRate} promo√ß√µes L2‚ÜíL1`);
```

---

## ‚ö° Performance

### Lat√™ncia por Camada

| Opera√ß√£o | L1 (Mem√≥ria) | L2 (Redis) | Layered |
|----------|--------------|------------|---------|
| **get** (HIT L1) | < 1ms | - | < 1ms |
| **get** (HIT L2) | < 1ms (miss) + 5ms | 5ms | ~6ms primeira, ~1ms pr√≥xima |
| **get** (MISS) | < 1ms + 5ms | 5ms | ~6ms |
| **set** | < 1ms | 5ms | ~5ms (paralelo) |
| **delete** | < 1ms | 5ms | ~5ms (paralelo) |

### Throughput

| Cen√°rio | Single Redis | Layered (L1+L2) | Speedup |
|---------|--------------|-----------------|---------|
| **100% hot data** | 200 req/s | 10.000 req/s | **50x** |
| **80% hot data** | 200 req/s | 8.000 req/s | **40x** |
| **50% hot data** | 200 req/s | 5.000 req/s | **25x** |
| **Cold data** | 200 req/s | 200 req/s | 1x |

### Efici√™ncia de Mem√≥ria

```typescript
// Dados duplicados em L1 e L2
// Mas hot data em L1 √© pequeno

// Exemplo:
// L2 (Redis): 10 GB de dados
// L1 (Memory): 100 MB de hot data (1% dos dados)
// Overhead: M√≠nimo, ganho enorme
```

---

## üéØ Casos de Uso

### 1. Aplica√ß√£o Load-Balanced

**Problema:** M√∫ltiplas inst√¢ncias precisam compartilhar cache.

**Solu√ß√£o:**

```typescript
// Cada inst√¢ncia tem seu L1 local + L2 compartilhado
const l1 = new MemoryCacheAdapter(300); // Local
const l2 = new RedisCacheAdapter(); // Compartilhado
const cache = new LayeredCacheAdapter(l1, l2);

// Inst√¢ncia 1 armazena
await cache.set('user:123', user); // L1 + L2

// Inst√¢ncia 2 l√™
await cache.get('user:123');
// L1: MISS (n√£o tem local)
// L2: HIT (compartilhado)
// Promove para L1 local da inst√¢ncia 2
```

### 2. Alta Performance com Resili√™ncia

**Requisito:** < 5ms de lat√™ncia, mas Redis pode falhar.

**Solu√ß√£o:**

```typescript
const cache = new LayeredCacheAdapter(l1, l2);

// Opera√ß√£o normal (Redis OK)
await cache.get('item'); // L1 hit ~1ms

// Redis cai
// L1 continua funcionando
await cache.get('item'); // L1 hit ~1ms (n√£o afetado)

// Dados novos v√£o s√≥ para L1
await cache.set('new', data); // L1 OK, L2 FAIL
// Retorna true, aplica√ß√£o continua
```

### 3. Cache de Sess√µes

**Requisito:** Sess√µes web compartilhadas, acesso ultra-r√°pido.

**Solu√ß√£o:**

```typescript
const sessionCache = new LayeredCacheAdapter(
  new MemoryCacheAdapter(300), // L1: 5min
  new RedisCacheAdapter() // L2: 30min
);

// Login - armazena sess√£o
await sessionCache.set(`session:${sessionId}`, session, 1800);

// Requests subsequentes - L1 hit
await sessionCache.get(`session:${sessionId}`); // ~1ms

// Ap√≥s 5min, L1 expira, mas L2 ainda tem
await sessionCache.get(`session:${sessionId}`); // L2 hit, promove L1
```

### 4. API Rate Limiting

**Requisito:** Contador de requests compartilhado, acesso r√°pido.

**Solu√ß√£o:**

```typescript
const rateLimitCache = new LayeredCacheAdapter(l1, l2);

async function checkRateLimit(userId: string): Promise<boolean> {
  const key = `ratelimit:${userId}`;

  // Busca contador
  let count = await rateLimitCache.get<number>(key) || 0;
  count++;

  // Atualiza
  await rateLimitCache.set(key, count, 60); // 1min window

  return count <= 100; // Max 100 req/min
}
```

---

## üí° Exemplos Pr√°ticos

### Setup B√°sico

```typescript
import { MemoryCacheAdapter } from './MemoryCacheAdapter';
import { RedisCacheAdapter } from './RedisCacheAdapter';
import { LayeredCacheAdapter } from './LayeredCacheAdapter';

// L1: Cache em mem√≥ria local (300s TTL padr√£o)
const l1 = new MemoryCacheAdapter(300, 'L1-Memory');

// L2: Cache Redis distribu√≠do
const l2 = new RedisCacheAdapter({
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD
}, 'L2-Redis');

// Layered: Combina L1 + L2
const cache = new LayeredCacheAdapter(l1, l2, 'MainCache');

export { cache };
```

### Cache de Usu√°rios

```typescript
interface User {
  id: string;
  name: string;
  email: string;
}

async function getUser(userId: string): Promise<User | null> {
  const cacheKey = `user:${userId}`;

  // 1. Tentar cache
  const cached = await cache.get<User>(cacheKey);
  if (cached) {
    log.debug('User from cache', { userId, layer: 'cache' });
    return cached;
  }

  // 2. Buscar banco
  const user = await database.users.findById(userId);
  if (!user) return null;

  // 3. Armazenar em cache
  await cache.set(cacheKey, user, 600); // 10min

  log.debug('User from database', { userId, layer: 'db' });
  return user;
}
```

### Cache de Queries

```typescript
async function getItems(filters: any): Promise<Item[]> {
  // Chave baseada em filters
  const cacheKey = `items:${JSON.stringify(filters)}`;

  const cached = await cache.get<Item[]>(cacheKey);
  if (cached) return cached;

  const items = await database.items.find(filters);

  // TTL menor para queries (dados podem mudar)
  await cache.set(cacheKey, items, 120); // 2min

  return items;
}
```

### Invalida√ß√£o em Cascade

```typescript
async function updateUser(userId: string, data: Partial<User>) {
  // 1. Atualizar banco
  const user = await database.users.update(userId, data);

  // 2. Invalidar cache relacionado
  await cache.delete(`user:${userId}`);
  await cache.delete(`user:${userId}:profile`);
  await cache.delete(`user:${userId}:settings`);

  // Ou com wildcard (Redis)
  // await cache.delete(`user:${userId}*`);

  return user;
}
```

### Monitoramento em Produ√ß√£o

```typescript
// Expor estat√≠sticas via endpoint
app.get('/admin/cache/stats', async (req, res) => {
  if (!req.user?.isAdmin) {
    return res.status(403).json({ error: 'Forbidden' });
  }

  const stats = cache.getStats();
  const ready = await cache.isReady();

  res.json({
    status: ready ? 'healthy' : 'degraded',
    stats,
    analysis: {
      l1Effectiveness: stats.l1.hits / stats.overall.hits * 100,
      l2Effectiveness: stats.l2.hits / stats.overall.hits * 100,
      recommendation: stats.l1.hitRate < 50
        ? 'Consider increasing L1 TTL'
        : 'Cache performing well'
    }
  });
});

// Logging peri√≥dico
setInterval(() => {
  const stats = cache.getStats();

  log.info('Cache stats', {
    l1HitRate: stats.l1.hitRate,
    l2HitRate: stats.l2.hitRate,
    overallHitRate: stats.overall.hitRate
  });

  if (stats.overall.hitRate < 50) {
    log.warn('Low cache hit rate', stats);
  }
}, 60000); // A cada minuto
```

---

## üîÑ Compara√ß√£o com Single-Layer

### Single-Layer Memory

| Aspecto | Single Memory | Layered (L1+L2) |
|---------|---------------|-----------------|
| **Performance** | ‚ö° < 1ms | ‚ö° < 1ms (L1 hit) |
| **Compartilhado** | ‚ùå N√£o | ‚úÖ Sim (via L2) |
| **Persist√™ncia** | ‚ùå Vol√°til | ‚úÖ Opcional (L2) |
| **Resili√™ncia** | ‚ùå Single point | ‚úÖ Redundante |
| **Complexidade** | üü¢ Baixa | üü° M√©dia |
| **Uso** | Dev, single instance | Produ√ß√£o multi-instance |

### Single-Layer Redis

| Aspecto | Single Redis | Layered (L1+L2) |
|---------|--------------|-----------------|
| **Performance** | üü° 1-10ms | ‚ö° < 1ms (L1 hit) |
| **Compartilhado** | ‚úÖ Sim | ‚úÖ Sim |
| **Persist√™ncia** | ‚úÖ Opcional | ‚úÖ Opcional |
| **Resili√™ncia** | ‚ùå Single point | ‚úÖ L1 fallback |
| **Complexidade** | üü¢ Baixa | üü° M√©dia |
| **Lat√™ncia** | Sempre rede | Evita rede (L1) |

### Quando Usar Layered

**Use Layered quando:**
- ‚úÖ Precisa de performance m√°xima (< 1ms)
- ‚úÖ Tem m√∫ltiplas inst√¢ncias load-balanced
- ‚úÖ Quer resili√™ncia (fallback L1)
- ‚úÖ Hot data √© pequeno (~10% dos dados)
- ‚úÖ Or√ßamento permite complexidade

**Use Single-Layer quando:**
- ‚úÖ Simplicidade √© prioridade
- ‚úÖ Single instance apenas
- ‚úÖ Performance 5-10ms √© aceit√°vel
- ‚úÖ Equipe pequena/inexperiente
- ‚úÖ Budget limitado

---

## üîß Troubleshooting

### Problema: L1 Hit Rate muito baixo (< 30%)

**Diagn√≥stico:**

```typescript
const stats = cache.getStats();
console.log(`L1 Hit Rate: ${stats.l1.hitRate}%`);
// L1 Hit Rate: 25%
```

**Causas poss√≠veis:**

1. **TTL L1 muito curto**
   ```typescript
   // ‚ùå L1 expira muito r√°pido
   const l1 = new MemoryCacheAdapter(30); // 30s

   // ‚úÖ TTL adequado
   const l1 = new MemoryCacheAdapter(300); // 5min
   ```

2. **Dados n√£o s√£o realmente hot**
   ```typescript
   // Verificar distribui√ß√£o de acessos
   const accessCount = new Map<string, number>();
   // Se acessos s√£o uniformes, layered n√£o ajuda
   ```

3. **Muitas chaves diferentes**
   ```typescript
   // Evitar chaves √∫nicas por request
   // ‚ùå const key = `query:${userId}:${timestamp}`;
   // ‚úÖ const key = `query:${userId}`;
   ```

---

### Problema: L2 sempre offline

**Sintomas:**

```typescript
await cache.isReady(); // true (L1 OK)
const stats = cache.getStats();
// L2 hits: 0, L2 misses: high
```

**Verifica√ß√£o:**

```typescript
// Testar L2 diretamente
const l2Ready = await l2.isReady();
if (!l2Ready) {
  log.error('L2 (Redis) est√° offline');
}

// Verificar conex√£o Redis
import Redis from 'ioredis';
const redis = new Redis();
await redis.ping(); // Deve retornar 'PONG'
```

**Solu√ß√£o:**
- Verificar Redis est√° rodando
- Verificar credenciais
- Verificar rede/firewall
- Verificar logs do Redis

---

### Problema: Dados inconsistentes entre L1 e L2

**Sintoma:**

```typescript
// Inst√¢ncia 1 atualiza
await cache.set('user:123', newData);

// Inst√¢ncia 2 l√™ dado antigo
const data = await cache.get('user:123');
// Retorna dado antigo (L1 local)
```

**Causa:** L1 local n√£o √© invalidado quando outra inst√¢ncia atualiza.

**Solu√ß√µes:**

1. **Invalida√ß√£o expl√≠cita**
   ```typescript
   // Ap√≥s update, invalidar cache
   await cache.delete('user:123');
   // Remove de L1 e L2
   ```

2. **TTL curto para dados mut√°veis**
   ```typescript
   // Dados que mudam frequentemente
   await cache.set('user:123', user, 60); // 1min
   ```

3. **Pub/Sub para invalida√ß√£o**
   ```typescript
   // Inst√¢ncia 1 publica invalida√ß√£o
   await redis.publish('cache:invalidate', 'user:123');

   // Todas inst√¢ncias escutam
   redis.subscribe('cache:invalidate', async (channel, key) => {
     await cache.delete(key);
   });
   ```

---

### Problema: Mem√≥ria L1 crescendo demais

**Diagn√≥stico:**

```typescript
const stats = cache.getStats();
const keys = await cache.keys();
console.log(`L1 tem ${keys.length} chaves`);

// Se muito alto, memory leak poss√≠vel
```

**Solu√ß√µes:**

1. **Definir maxKeys no L1**
   ```typescript
   const l1 = new MemoryCacheAdapter(300, {
     maxKeys: 10000, // Limite de chaves
     evictionPolicy: 'lru' // Remove least recently used
   });
   ```

2. **Monitorar uso de mem√≥ria**
   ```typescript
   const memUsage = process.memoryUsage();
   console.log(`Heap: ${memUsage.heapUsed / 1024 / 1024} MB`);

   if (memUsage.heapUsed > 1024 * 1024 * 1024) {
     log.warn('High memory usage, consider flushing L1');
     await l1.flush();
   }
   ```

3. **TTL apropriado**
   ```typescript
   // Garantir que tudo expira
   await cache.set(key, value, 300); // Sempre com TTL
   ```

---

**√öltima atualiza√ß√£o:** 2025-10-07